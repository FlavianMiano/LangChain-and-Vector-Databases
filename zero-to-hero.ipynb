{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1b20d45",
   "metadata": {},
   "source": [
    "# The LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e05f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e925ac76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c2aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before executing the following code, make sure to have\n",
    "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "\n",
    "llm = OpenAI(model=\"text-davinci-003\", \n",
    "             temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed036ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Walking or jogging: 3-5 days a week for 30-45 minutes. Start slow and work up to jogging faster and for longer distances. \n",
      "\n",
      "2. Interval sprints: 2-3 days a week for 20-30 minutes. Run for 1-2 minutes at a sprinting speed, followed by 1-2 minutes of jogging or walking at a slow pace. Repeat this pattern for the duration of the workout.\n",
      "\n",
      "3. Hiking: 2 days a week for 45-60 minutes. Choose challenging terrain with hills and inclines to increase the intensity of the workout.\n",
      "\n",
      "4. Rock climbing: 1 day a week for 60 minutes. Focus on endurance and stamina as you climb, but also take breaks when needed.\n",
      "\n",
      "5. Swimming: 1-2 days a week for 30-45 minutes. Choose a stroke and focus on going the distance; don’t worry about speed. \n",
      "\n",
      "6. Stand-up paddle boarding: 1 day a week for 30-45 minutes. This is a great full-body workout and a great way to increase your cardiovascular endurance.\n"
     ]
    }
   ],
   "source": [
    "text = \"Suggest a personalized workout routine for someone looking to improve cardiovascular endurance and prefers outdoor activities.\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c396ad",
   "metadata": {},
   "source": [
    "# The chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59dc9804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "DataSight Solutions.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0.9)\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the chain only specifying the input variable.\n",
    "print(chain.run(\"Analytics Company\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad785a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tower, Titan, or Colossus.\n"
     ]
    }
   ],
   "source": [
    "prompt2 = PromptTemplate(\n",
    "    input_variables=[\"boy\"],\n",
    "    template = \"what is the best name for {boy}\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt2)\n",
    "\n",
    "print(chain.run(\"tall boy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "524ea242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "\n",
      "No, Langchain currently does not understand Kiswahili.\n"
     ]
    }
   ],
   "source": [
    "prompr3 = PromptTemplate(\n",
    "    input_variables=[\"language\"],\n",
    "    template='can langchain understand {language}'\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompr3)\n",
    "\n",
    "print(chain.run(\"Kiswahili\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1e9058",
   "metadata": {},
   "source": [
    "# The Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "294546e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Tell me about yourself.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Tell me about yourself.\n",
      "AI:  Hi there! I'm an AI created to help people with their daily tasks. I'm programmed to understand natural language and respond to questions and commands. I'm also able to learn from my interactions with people, so I'm constantly growing and improving. I'm excited to help you out!\n",
      "Human: What can you do?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Tell me about yourself.\n",
      "AI:  Hi there! I'm an AI created to help people with their daily tasks. I'm programmed to understand natural language and respond to questions and commands. I'm also able to learn from my interactions with people, so I'm constantly growing and improving. I'm excited to help you out!\n",
      "Human: What can you do?\n",
      "AI:  I can help you with a variety of tasks, such as scheduling appointments, setting reminders, and providing information. I'm also able to answer questions about topics like current events, sports, and entertainment. I'm always learning new things, so I'm sure I can help you with whatever you need.\n",
      "Human: what LLM model was used to build the snapchat ai?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Tell me about yourself.\n",
      "AI:  Hi there! I'm an AI created to help people with their daily tasks. I'm programmed to understand natural language and respond to questions and commands. I'm also able to learn from my interactions with people, so I'm constantly growing and improving. I'm excited to help you out!\n",
      "Human: What can you do?\n",
      "AI:  I can help you with a variety of tasks, such as scheduling appointments, setting reminders, and providing information. I'm also able to answer questions about topics like current events, sports, and entertainment. I'm always learning new things, so I'm sure I can help you with whatever you need.\n",
      "Human: what LLM model was used to build the snapchat ai?\n",
      "AI:  I'm sorry, I don't know the answer to that question.\n",
      "Human: How can you help me with data analysis?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "memory=ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='Tell me about yourself.', additional_kwargs={}, example=False), AIMessage(content=\" Hi there! I'm an AI created to help people with their daily tasks. I'm programmed to understand natural language and respond to questions and commands. I'm also able to learn from my interactions with people, so I'm constantly growing and improving. I'm excited to help you out!\", additional_kwargs={}, example=False), HumanMessage(content='What can you do?', additional_kwargs={}, example=False), AIMessage(content=\" I can help you with a variety of tasks, such as scheduling appointments, setting reminders, and providing information. I'm also able to answer questions about topics like current events, sports, and entertainment. I'm always learning new things, so I'm sure I can help you with whatever you need.\", additional_kwargs={}, example=False), HumanMessage(content='what LLM model was used to build the snapchat ai?', additional_kwargs={}, example=False), AIMessage(content=\" I'm sorry, I don't know the answer to that question.\", additional_kwargs={}, example=False), HumanMessage(content='How can you help me with data analysis?', additional_kwargs={}, example=False), AIMessage(content=' I can help you with data analysis by providing insights and recommendations based on the data you provide. I can also help you visualize the data in a way that makes it easier to understand. Additionally, I can help you identify patterns and trends in the data that can help you make better decisions.', additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=False, human_prefix='Human', ai_prefix='AI', memory_key='history') callbacks=None callback_manager=None verbose=True tags=None prompt=PromptTemplate(input_variables=['history', 'input'], output_parser=None, partial_variables={}, template='The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:', template_format='f-string', validate_template=True) llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all') output_key='response' output_parser=NoOpOutputParser() return_final_only=True llm_kwargs={} input_key='input'\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = OpenAI(model = 'text-davinci-003', temperature=0)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    verbose = True,\n",
    "    memory = ConversationBufferMemory()\n",
    ")\n",
    "\n",
    "# Start the conversation\n",
    "conversation.predict(input=\"Tell me about yourself.\")\n",
    "\n",
    "# Continue the conversation\n",
    "conversation.predict(input=\"What can you do?\")\n",
    "conversation.predict(input='what LLM model was used to build the snapchat ai?')\n",
    "conversation.predict(input=\"How can you help me with data analysis?\")\n",
    "\n",
    "\n",
    "# Display the conversation\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545f56b3",
   "metadata": {},
   "source": [
    "# DeepLake VectoreStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12ab0b34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://zatana54/langchain_course_custom_tool already exists, loading from the storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://zatana54/langchain_course_custom_tool', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      " embedding  embedding  (2, 1536)  float32   None   \n",
      "    id        text      (2, 1)      str     None   \n",
      " metadata     json      (2, 1)      str     None   \n",
      "   text       text      (2, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['b3d259df-106f-11ee-b082-a0a4c5a8be61',\n",
       " 'b3d259e0-106f-11ee-b8f9-a0a4c5a8be61']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "import deeplake\n",
    "import os\n",
    "\n",
    "active_loop_token = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
    "\n",
    "# Before executing the following code, make sure to have your\n",
    "# Activeloop key saved in the “ACTIVELOOP_TOKEN” environment variable.\n",
    "\n",
    "#os.environ[\"ACTIVELOOP_TOKEN\"] = \"eyJhbGciOiJIUzUxMiIsImlhdCI6MTY4NzM0Njc3OSwiZXhwIjoxNjkzMzk0NzAzfQ.eyJpZCI6ImZsYXZpYW5taWFubyJ9.bRjbnlse5GbhnTcCUv4N9qGuDSEUfqueuqgyDV8NJgx4zfjRcU1l0Wl2l3gmEKcPVxsMrjIMQkmC4_d6Zycbag\"\n",
    "\n",
    "# instantiate the LLM and embeddings models\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# create our documents\n",
    "texts = [\n",
    "    \"Napoleon Bonaparte was born in 15 August 1769\",\n",
    "    \"Louis XIV was born in 5 September 1638\"\n",
    "]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.create_documents(texts)\n",
    "\n",
    "# create Deep Lake dataset\n",
    "my_activeloop_org_id = \"zatana54\" # TODO: use your organization id here\n",
    "my_activeloop_dataset_name = \"langchain_course_custom_tool\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings )\n",
    "\n",
    "# add documents to our Deep Lake dataset\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d9b926",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "<script async src=\"https://cse.google.com/cse.js?cx=4766978c89dd34d7e\">\n",
    "</script>\n",
    "<div class=\"gcse-search\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9f9c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "\tllm=llm,\n",
    "\tchain_type=\"stuff\",\n",
    "\tretriever=db.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7a1055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Retrieval QA System\",\n",
    "        func=retrieval_qa.run,\n",
    "        description=\"Useful for answering questions.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "\ttools,\n",
    "\tllm,\n",
    "\tagent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "\tverbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "630d6786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out when Napoleone was born.\n",
      "Action: Retrieval QA System\n",
      "Action Input: When was Napoleone born?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Napoleon Bonaparte was born on 15 August 1769.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Napoleon Bonaparte was born on 15 August 1769.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Napoleon Bonaparte was born on 15 August 1769.\n"
     ]
    }
   ],
   "source": [
    "response = agent.run(\"When was Napoleone born?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ea71e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://zatana54/langchain_course_custom_tool already exists, loading from the storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://zatana54/langchain_course_custom_tool', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      " embedding  embedding  (4, 1536)  float32   None   \n",
      "    id        text      (4, 1)      str     None   \n",
      " metadata     json      (4, 1)      str     None   \n",
      "   text       text      (4, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['428bfeff-1070-11ee-8297-a0a4c5a8be61',\n",
       " '428bff00-1070-11ee-9092-a0a4c5a8be61']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the existing Deep Lake dataset and specify the embedding function\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
    "\n",
    "# create new documents\n",
    "texts = [\n",
    "    \"Lady Gaga was born in 28 March 1986\",\n",
    "    \"Michael Jeffrey Jordan was born in 17 February 1963\"\n",
    "]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.create_documents(texts)\n",
    "\n",
    "# add documents to our Deep Lake dataset\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea28d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the wrapper class for GPT3\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "# create a retriever from the db\n",
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "\tllm=llm, chain_type=\"stuff\", retriever=db.as_retriever()\n",
    ")\n",
    "\n",
    "# instantiate a tool that uses the retriever\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Retrieval QA System\",\n",
    "        func=retrieval_qa.run,\n",
    "        description=\"Useful for answering questions.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# create an agent that uses the tool\n",
    "agent = initialize_agent(\n",
    "\ttools,\n",
    "\tllm,\n",
    "\tagent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "\tverbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12560a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out when Michael Jordan was born.\n",
      "Action: Retrieval QA System\n",
      "Action Input: When was Michael Jordan born?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Michael Jordan was born on 17 February 1963.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Michael Jordan was born on 17 February 1963.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Michael Jordan was born on 17 February 1963.\n"
     ]
    }
   ],
   "source": [
    "response = agent.run(\"When was Michael Jordan born?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a2640f",
   "metadata": {},
   "source": [
    "# Agents in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b771d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import Agent, AgentType\n",
    "\n",
    "from langchain.agents import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb9cda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "google_cse_id = os.getenv(\"GOOGLE_CSE_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04d055e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb8fa7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to set the environment variables\n",
    "# “GOOGLE_API_KEY” and “GOOGLE_CSE_ID” to be able to use\n",
    "# Google Search via API.\n",
    "search = GoogleSearchAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "905064b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name = \"google-search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to search google to answer questions about current events\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b2256e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, \n",
    "                         llm, \n",
    "                         agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                         verbose=True,\n",
    "                         max_iterations=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fed3cc43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the latest news about the Mars rover\n",
      "Action: google-search\n",
      "Action Input: \"latest news Mars rover\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNASA's Curiosity rover is discovering odd rocks halfway into a region called the \"clay-bearing unit.\" ... This panorama of a location called \"Teal Ridge\" was ... Dec 15, 2021 ... Mars Sample Return is going to have great stuff to choose from!” Get the Latest JPL News. SUBSCRIBE TO THE NEWSLETTER. The mission has concluded that the solar-powered lander has run out of energy after more than four years on the Red Planet. A book-shaped rock on Mars was likely carved by ancient water running through the area, scientists on NASA's Curiosity rover mission say. Blog updates written by Mars Perseverance mission team members. ... After our exploration of a boulder field last week, Perseverance is continuing the Upper ... Apr 28, 2023 ... Friday's news comes days after mission leaders acknowledged that the Zhurong rover has yet to wake up since going into hibernation for the ... Sep 16, 2022 ... Since July, NASA's Perseverance rover has drilled and collected four slim cores of sedimentary rock, formed in what was once a lake on Mars. Apr 25, 2023 ... China's Mars rover, which has been in longer-than-expected hibernation on the red planet since May 2022, has likely suffered excessive ... Mar 7, 2023 ... 27, helps provide scientists with information about the particle sizes within the clouds. Sign up for National Breaking News Alerts. Nasa Mars lander study reveals 'main source of heat' on Red Planet · NASA/ESA/A. Simon (Goddard Space Flight Center) and M.H. Wong.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The latest news about the Mars rover is that NASA's Curiosity rover is discovering odd rocks halfway into a region called the \"clay-bearing unit,\" a book-shaped rock on Mars was likely carved by ancient water running through the area, the solar-powered lander has run out of energy after more than four years on the Red Planet, Perseverance is continuing the Upper exploration of a boulder field, China's Mars rover has been in longer-than-expected hibernation on the red planet since May 2022, and Perseverance has drilled and collected four slim cores of sedimentary rock.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The latest news about the Mars rover is that NASA's Curiosity rover is discovering odd rocks halfway into a region called the \"clay-bearing unit,\" a book-shaped rock on Mars was likely carved by ancient water running through the area, the solar-powered lander has run out of energy after more than four years on the Red Planet, Perseverance is continuing the Upper exploration of a boulder field, China's Mars rover has been in longer-than-expected hibernation on the red planet since May 2022, and Perseverance has drilled and collected four slim cores of sedimentary rock.\n"
     ]
    }
   ],
   "source": [
    "response = agent(\"What's the latest news about the Mars rover?\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "413da4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should look for records of the most lines of code written by a single person\n",
      "Action: google-search\n",
      "Action Input: \"most lines of code written by a single person\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIt was written by Dennis Ritchie and Brian Kernighan in their book, the C programming Language, published in 1978. I would say more programmers have executed ... Jul 17, 2018 ... It is always fascinating to know how many lines of codes are ... The Age Of Empire online game took more than 1 million lines of code. Originally Answered: What is the largest program ever written? Probably an OS. MS Windows is notorious for being extremely large and complex. One of my ... Jul 15, 2021 ... This program would constitute a single function that can be called upon whenever needed, rather than needeing a written a set of instructions ... Mar 27, 2016 ... Koçulu had been publishing code he wrote to npm, a popular service that's widely used ... The error spit out many lines, but one stood out:. Jul 18, 2020 ... Ever wonder how many lines of computer code have been written? ... Some programming languages, like Python, allow a person to code in ... Aug 12, 2009 ... This code does not recurse, it will only return the results for a single directory, but it is a good start if someone wanted to go further. Copy ... Sep 16, 2015 ... By comparison, Microsoft Windows—one of the most complex software tools ever built for a single computer—is about 50 million lines. You can run something like. git ls-files | xargs wc -l. Which will give you the total count →. lines of code. You can also add more instructions. Dec 31, 2021 ... Individual dwarves have emotional states, favorite gems, ... That is, because you wrote every line, is it easier to maintain and change?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The most written lines of code by a single person is 50 million lines, written by Microsoft Windows.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The most written lines of code by a single person is 50 million lines, written by Microsoft Windows.\n"
     ]
    }
   ],
   "source": [
    "response = agent('most written lines of code by a single person?')\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e45de45",
   "metadata": {},
   "source": [
    "# Tools in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "98723784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c41570c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"Write a summary of the following text: {query}\"\n",
    ")\n",
    "\n",
    "summarize_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "052a6328",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GoogleSearchAPIWrapper()\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for finding information about recent events\"\n",
    "    ),\n",
    "    Tool(\n",
    "       name='Summarizer',\n",
    "       func=summarize_chain.run,\n",
    "       description='useful for summarizing texts'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21f48f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33801fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should search for recent news about the Mars rover and then summarize the results.\n",
      "Action: Search\n",
      "Action Input: Latest news about the Mars rover\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mMars 2020 Perseverance Rover · The largest and most capable rover ever sent to Mars. ... Curiosity Rover · Measures Mars' atmosphere to understand its climate ... Dec 15, 2021 ... Mars Sample Return is going to have great stuff to choose from!” Get the Latest JPL News. SUBSCRIBE TO THE NEWSLETTER. The mission has concluded that the solar-powered lander has run out of energy after more than four years on the Red Planet. Oct 19, 2022 ... NASA's Curiosity Mars rover used its Mast Camera, or Mastcam, to capture this panorama of a hill nicknamed ... Get the Latest JPL News. NASA's Mars 2020 Perseverance rover will look for signs of past microbial life, cache rock and soil samples, and prepare for future human exploration. A book-shaped rock on Mars was likely carved by ancient water running through the area, scientists on NASA's Curiosity rover mission say. Feb 8, 2023 ... Curiosity Rover Finds New Clues to Mars' Watery Past ... at Gediz Vallis Ridge twice last year but could only survey it from a distance. Sep 16, 2022 ... Since July, NASA's Perseverance rover has drilled and collected four slim cores of sedimentary rock, formed in what was once a lake on Mars. Apr 28, 2023 ... A new study suggests water on Mars may be more widespread and recent than previously thought. Scientists reported the finding from China's ... Mar 7, 2023 ... 27, helps provide scientists with information about the particle sizes within the clouds. Sign up for National Breaking News Alerts.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should summarize the results of the search.\n",
      "Action: Summarizer\n",
      "Action Input: Mars 2020 Perseverance Rover is the largest and most capable rover ever sent to Mars. Curiosity Rover measures Mars' atmosphere to understand its climate. The mission has concluded that the solar-powered lander has run out of energy after more than four years on the Red Planet. NASA's Curiosity Mars rover used its Mast Camera to capture a panorama of a hill. NASA's Mars 2020 Perseverance rover will look for signs of past microbial life, cache rock and soil samples, and prepare for future human exploration. A book-shaped rock on Mars was likely carved by ancient water running through the area. Curiosity Rover found new clues to Mars' watery past. Since July, NASA's Perseverance rover has drilled and collected four slim cores of sedimentary rock. A new study suggests water on Mars may be more widespread and recent than previously thought.\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "\n",
      "NASA's Mars 2020 Perseverance Rover is the largest and most capable rover ever sent to Mars. It is solar-powered and has been on the Red Planet for more than four years. Its mission is to look for signs of past microbial life, cache rock and soil samples, and prepare for future human exploration. The Curiosity Rover has used its Mast Camera to capture a panorama of a hill and has found new clues to Mars' watery past. A book-shaped rock on Mars was likely carved by ancient water running through the area. Perseverance has also drilled and collected four slim cores of sedimentary rock, and a new study suggests water on Mars may be more widespread and recent than previously thought.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: NASA's Mars 2020 Perseverance Rover is the largest and most capable rover ever sent to Mars. Its mission is to look for signs of past microbial life, cache rock and soil samples, and prepare for future human exploration. The Curiosity Rover has used its Mast Camera to capture a panorama of a hill and has found new clues to Mars' watery past. A book-shaped rock on Mars was likely carved by ancient water running through the area. Perseverance has also drilled and collected four slim cores of sedimentary rock, and a new study suggests water on Mars may be more widespread and recent than previously thought.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "NASA's Mars 2020 Perseverance Rover is the largest and most capable rover ever sent to Mars. Its mission is to look for signs of past microbial life, cache rock and soil samples, and prepare for future human exploration. The Curiosity Rover has used its Mast Camera to capture a panorama of a hill and has found new clues to Mars' watery past. A book-shaped rock on Mars was likely carved by ancient water running through the area. Perseverance has also drilled and collected four slim cores of sedimentary rock, and a new study suggests water on Mars may be more widespread and recent than previously thought.\n"
     ]
    }
   ],
   "source": [
    "response = agent(\"What's the latest news about the Mars rover? Then please summarize the results.\")\n",
    "print(response['output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
